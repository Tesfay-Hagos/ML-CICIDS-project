{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1628e38",
   "metadata": {},
   "source": [
    "## 1.1 Install Missed Packages With pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b0bcdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas (pandas) version: 2.3.3\n",
      "numpy (numpy) version: 1.26.4\n",
      "matplotlib (matplotlib) version: 3.6.3\n",
      "seaborn (seaborn) version: 0.13.2\n",
      "scikit-learn (sklearn) version: 1.7.2\n",
      "scipy (scipy) version: 1.11.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import ensurepip\n",
    "\n",
    "# Ensure pip exists and install required packages if missing\n",
    "import importlib.util\n",
    "\n",
    "# 1) Ensure pip is available\n",
    "try:\n",
    "    import pip  # noqa: F401\n",
    "except Exception:\n",
    "    try:\n",
    "        ensurepip.bootstrap()\n",
    "    except Exception:\n",
    "        # fallback to get-pip.py\n",
    "        import urllib.request, tempfile, os\n",
    "        url = \"https://bootstrap.pypa.io/get-pip.py\"\n",
    "        fd, tmp_path = tempfile.mkstemp(suffix=\".py\")\n",
    "        os.close(fd)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, tmp_path)\n",
    "            subprocess.check_call([sys.executable, tmp_path])\n",
    "        finally:\n",
    "            try:\n",
    "                os.remove(tmp_path)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "# 2) List of packages to ensure (pip-name -> import-name)\n",
    "required = {\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"numpy\": \"numpy\",\n",
    "    \"matplotlib\": \"matplotlib\",\n",
    "    \"seaborn\": \"seaborn\",\n",
    "    \"scikit-learn\": \"sklearn\",\n",
    "    \"scipy\": \"scipy\",\n",
    "}\n",
    "\n",
    "# 3) Detect missing modules\n",
    "missing = [pkg for pkg, mod in required.items() if importlib.util.find_spec(mod) is None]\n",
    "\n",
    "# 4) Install missing packages in one pip call\n",
    "if missing:\n",
    "    print(\"Installing missing packages:\", missing)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + missing)\n",
    "\n",
    "# 5) Report installed versions (or failures)\n",
    "for pkg, mod in required.items():\n",
    "    try:\n",
    "        module = __import__(mod)\n",
    "        version = getattr(module, \"__version__\", \"unknown\")\n",
    "        print(f\"{pkg} ({mod}) version: {version}\")\n",
    "    except Exception:\n",
    "        print(f\"Failed to import {mod}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f13c6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry installation with --break-system-packages flag if needed\n",
    "if missing:\n",
    "    print(\"Retrying installation with --break-system-packages...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--break-system-packages\"] + missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d65e66",
   "metadata": {},
   "source": [
    "## 1.2 Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8086af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper-function-markdown",
   "metadata": {},
   "source": [
    "## 1.3 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "google-drive-helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mount_google_drive():\n",
    "    \"\"\"\n",
    "    Checks if running in Google Colab and mounts Google Drive if so.\n",
    "    Returns the base path to the user's Drive content if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        print(\"Google Colab environment detected. Mounting Google Drive...\")\n",
    "        drive.mount('/content/drive')\n",
    "        # Return the common base path for Google Drive\n",
    "        return '/content/drive/MyDrive'\n",
    "    except ImportError:\n",
    "        # This will be the case on your local machine\n",
    "        print(\"Not running in a Google Colab environment. Skipping Google Drive mount.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while mounting Google Drive: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c42389",
   "metadata": {},
   "source": [
    "## 2 Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2d33adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for .csv files in: ./data\n",
      "  - Reading file: ./data/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "  - Reading file: ./data/Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "  - Reading file: ./data/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "  - Reading file: ./data/Wednesday-workingHours.pcap_ISCX.csv\n",
      "  - Reading file: ./data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "  - Reading file: ./data/Monday-WorkingHours.pcap_ISCX.csv\n",
      "  - Reading file: ./data/Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "  - Reading file: ./data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "\n",
      "Successfully loaded 8 DataFrame(s).\n"
     ]
    }
   ],
   "source": [
    "# List to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# --- Define Paths ---\n",
    "local_data_path = './data'  # The local directory to check first\n",
    "# IMPORTANT: Update this path to your dataset's location in Google Drive\n",
    "google_drive_folder = 'CIC-IDS-2017'  # The specific folder name in your MyDrive\n",
    "\n",
    "def load_data_from_path(path, df_list):\n",
    "    \"\"\"Walks a directory and loads all found .csv files into a list of DataFrames.\"\"\"\n",
    "    if not (os.path.exists(path) and os.path.isdir(path)):\n",
    "        print(f\"Data directory not found at: {path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Searching for .csv files in: {path}\")\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.csv'):\n",
    "                file_path = os.path.join(dirname, filename)\n",
    "                print(f\"  - Reading file: {file_path}\")\n",
    "                try:\n",
    "                    df_list.append(pd.read_csv(file_path))\n",
    "                except Exception as e:\n",
    "                    print(f\"    - Error reading {file_path}: {e}\")\n",
    "\n",
    "# --- 1. Attempt to load from local path ---\n",
    "load_data_from_path(local_data_path, dfs)\n",
    "\n",
    "# --- 2. If no local data, attempt to load from Google Drive ---\n",
    "if not dfs:\n",
    "    print(\"\\nNo local data loaded. Attempting to use Google Drive.\")\n",
    "    drive_base_path = mount_google_drive()\n",
    "    if drive_base_path:\n",
    "        # Construct the full path to your data on Google Drive\n",
    "        gdrive_data_path = os.path.join(drive_base_path, google_drive_folder)\n",
    "        load_data_from_path(gdrive_data_path, dfs)\n",
    "\n",
    "# --- 3. Final check ---\n",
    "if not dfs:\n",
    "    print(\"\\nWarning: No data could be loaded. The 'dfs' list is empty.\")\n",
    "else:\n",
    "    print(f\"\\nSuccessfully loaded {len(dfs)} DataFrame(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b56dfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -> 288602 rows, 79 columns\n",
      "df2 -> 191033 rows, 79 columns\n",
      "df3 -> 170366 rows, 79 columns\n",
      "df4 -> 692703 rows, 79 columns\n",
      "df5 -> 225745 rows, 79 columns\n",
      "df6 -> 529918 rows, 79 columns\n",
      "df7 -> 445909 rows, 79 columns\n",
      "df8 -> 286467 rows, 79 columns\n"
     ]
    }
   ],
   "source": [
    "# Data dimensions of each individual dataset\n",
    "for i, data in enumerate(dfs, start=1):\n",
    "    rows, cols = data.shape\n",
    "    print(f'df{i} -> {rows} rows, {cols} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4ee5d",
   "metadata": {},
   "source": [
    "## 1.2. Merging the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2852a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames concatenated successfully.\n"
     ]
    }
   ],
   "source": [
    "# It's good practice to check if the list is populated before concatenation.\n",
    "if dfs:\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    data = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    print(\"DataFrames concatenated successfully.\")\n",
    "\n",
    "    # Deleting the list of DataFrames to free up memory\n",
    "    del dfs\n",
    "else:\n",
    "    # Handle the case where no DataFrames were created\n",
    "    print(\"Warning: No data was found to concatenate. The 'data' DataFrame has not be created.\")\n",
    "    data = pd.DataFrame() # Optionally, create an empty DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0007115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60148</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>99947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>37017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>111161336</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1753752.625</td>\n",
       "      <td>2123197.578</td>\n",
       "      <td>4822992</td>\n",
       "      <td>95</td>\n",
       "      <td>9463032.7</td>\n",
       "      <td>2657727.996</td>\n",
       "      <td>13600000</td>\n",
       "      <td>5700287</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0                 22             166                   1   \n",
       "1              60148              83                   1   \n",
       "2                123           99947                   1   \n",
       "3                123           37017                   1   \n",
       "4                  0       111161336                 147   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                        1                            0   \n",
       "1                        2                            0   \n",
       "2                        1                           48   \n",
       "3                        1                           48   \n",
       "4                        0                            0   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "2                            48                      48   \n",
       "3                            48                      48   \n",
       "4                             0                       0   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                       0                      0.0                     0.0   \n",
       "1                       0                      0.0                     0.0   \n",
       "2                      48                     48.0                     0.0   \n",
       "3                      48                     48.0                     0.0   \n",
       "4                       0                      0.0                     0.0   \n",
       "\n",
       "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "0  ...                     32        0.000        0.000            0   \n",
       "1  ...                     32        0.000        0.000            0   \n",
       "2  ...                     40        0.000        0.000            0   \n",
       "3  ...                     32        0.000        0.000            0   \n",
       "4  ...                      0  1753752.625  2123197.578      4822992   \n",
       "\n",
       "    Active Min  Idle Mean     Idle Std   Idle Max   Idle Min   Label  \n",
       "0            0        0.0        0.000          0          0  BENIGN  \n",
       "1            0        0.0        0.000          0          0  BENIGN  \n",
       "2            0        0.0        0.000          0          0  BENIGN  \n",
       "3            0        0.0        0.000          0          0  BENIGN  \n",
       "4           95  9463032.7  2657727.996   13600000    5700287  BENIGN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb20a81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>746827</th>\n",
       "      <td>80</td>\n",
       "      <td>217872</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>382</td>\n",
       "      <td>11595</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>127.333333</td>\n",
       "      <td>220.547803</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoS Hulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946912</th>\n",
       "      <td>80</td>\n",
       "      <td>84743121</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>355</td>\n",
       "      <td>11595</td>\n",
       "      <td>343</td>\n",
       "      <td>0</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>152.082215</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>11013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11013</td>\n",
       "      <td>11013</td>\n",
       "      <td>84600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84600000</td>\n",
       "      <td>84600000</td>\n",
       "      <td>DoS Hulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216843</th>\n",
       "      <td>53</td>\n",
       "      <td>2714807</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>416</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.549193</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699389</th>\n",
       "      <td>443</td>\n",
       "      <td>11053475</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>18983</td>\n",
       "      <td>8109</td>\n",
       "      <td>2389</td>\n",
       "      <td>0</td>\n",
       "      <td>903.952381</td>\n",
       "      <td>1125.348945</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170268</th>\n",
       "      <td>80</td>\n",
       "      <td>15220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800686</th>\n",
       "      <td>80</td>\n",
       "      <td>99394898</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>339</td>\n",
       "      <td>11595</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>42.375000</td>\n",
       "      <td>117.449001</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "      <td>99200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99200000</td>\n",
       "      <td>99200000</td>\n",
       "      <td>DoS Hulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434488</th>\n",
       "      <td>80</td>\n",
       "      <td>109263</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>11601</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>10.263203</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DDoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968368</th>\n",
       "      <td>53</td>\n",
       "      <td>69709</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>768</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934343</th>\n",
       "      <td>80</td>\n",
       "      <td>83027396</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>311</td>\n",
       "      <td>11595</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>98.346835</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>82900000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82900000</td>\n",
       "      <td>82900000</td>\n",
       "      <td>DoS Hulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693547</th>\n",
       "      <td>80</td>\n",
       "      <td>61462028</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>231</td>\n",
       "      <td>4559</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>46.200000</td>\n",
       "      <td>93.280223</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "746827                  80          217872                   3   \n",
       "946912                  80        84743121                   5   \n",
       "2216843                 53         2714807                   6   \n",
       "699389                 443        11053475                  21   \n",
       "1170268                 80           15220                   1   \n",
       "800686                  80        99394898                   8   \n",
       "1434488                 80          109263                   3   \n",
       "1968368                 53           69709                   4   \n",
       "934343                  80        83027396                  10   \n",
       "693547                  80        61462028                   5   \n",
       "\n",
       "          Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "746827                         7                          382   \n",
       "946912                         7                          355   \n",
       "2216843                        4                          258   \n",
       "699389                        22                        18983   \n",
       "1170268                        1                            6   \n",
       "800686                         6                          339   \n",
       "1434488                        4                           26   \n",
       "1968368                        4                          168   \n",
       "934343                         6                          311   \n",
       "693547                         5                          231   \n",
       "\n",
       "          Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "746827                          11595                     382   \n",
       "946912                          11595                     343   \n",
       "2216843                           416                      45   \n",
       "699389                           8109                    2389   \n",
       "1170268                             6                       6   \n",
       "800686                          11595                     333   \n",
       "1434488                         11601                      20   \n",
       "1968368                           768                      42   \n",
       "934343                          11595                     311   \n",
       "693547                           4559                     213   \n",
       "\n",
       "          Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
       "746827                        0               127.333333   \n",
       "946912                        0                71.000000   \n",
       "2216843                      42                43.000000   \n",
       "699389                        0               903.952381   \n",
       "1170268                       6                 6.000000   \n",
       "800686                        0                42.375000   \n",
       "1434488                       0                 8.666667   \n",
       "1968368                      42                42.000000   \n",
       "934343                        0                31.100000   \n",
       "693547                        0                46.200000   \n",
       "\n",
       "          Fwd Packet Length Std  ...   min_seg_size_forward  Active Mean  \\\n",
       "746827               220.547803  ...                     32          0.0   \n",
       "946912               152.082215  ...                     20      11013.0   \n",
       "2216843                1.549193  ...                     20          0.0   \n",
       "699389              1125.348945  ...                     20          0.0   \n",
       "1170268                0.000000  ...                     20          0.0   \n",
       "800686               117.449001  ...                     20       1945.0   \n",
       "1434488               10.263203  ...                     20          0.0   \n",
       "1968368                0.000000  ...                     20          0.0   \n",
       "934343                98.346835  ...                     32       1984.0   \n",
       "693547                93.280223  ...                     20          0.0   \n",
       "\n",
       "          Active Std   Active Max   Active Min   Idle Mean   Idle Std  \\\n",
       "746827           0.0            0            0         0.0        0.0   \n",
       "946912           0.0        11013        11013  84600000.0        0.0   \n",
       "2216843          0.0            0            0         0.0        0.0   \n",
       "699389           0.0            0            0         0.0        0.0   \n",
       "1170268          0.0            0            0         0.0        0.0   \n",
       "800686           0.0         1945         1945  99200000.0        0.0   \n",
       "1434488          0.0            0            0         0.0        0.0   \n",
       "1968368          0.0            0            0         0.0        0.0   \n",
       "934343           0.0         1984         1984  82900000.0        0.0   \n",
       "693547           0.0            0            0         0.0        0.0   \n",
       "\n",
       "          Idle Max   Idle Min     Label  \n",
       "746827           0          0  DoS Hulk  \n",
       "946912    84600000   84600000  DoS Hulk  \n",
       "2216843          0          0    BENIGN  \n",
       "699389           0          0    BENIGN  \n",
       "1170268          0          0    BENIGN  \n",
       "800686    99200000   99200000  DoS Hulk  \n",
       "1434488          0          0      DDoS  \n",
       "1968368          0          0    BENIGN  \n",
       "934343    82900000   82900000  DoS Hulk  \n",
       "693547           0          0    BENIGN  \n",
       "\n",
       "[10 rows x 79 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display 10 random rows\n",
    "data.sample(n=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff7236e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dimensions: (2830743, 79)\n"
     ]
    }
   ],
   "source": [
    "# Get dataset dimensions\n",
    "print(f\"Dataset Dimensions: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "018c8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2830743 entries, 0 to 2830742\n",
      "Data columns (total 79 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0    Destination Port             int64  \n",
      " 1    Flow Duration                int64  \n",
      " 2    Total Fwd Packets            int64  \n",
      " 3    Total Backward Packets       int64  \n",
      " 4   Total Length of Fwd Packets   int64  \n",
      " 5    Total Length of Bwd Packets  int64  \n",
      " 6    Fwd Packet Length Max        int64  \n",
      " 7    Fwd Packet Length Min        int64  \n",
      " 8    Fwd Packet Length Mean       float64\n",
      " 9    Fwd Packet Length Std        float64\n",
      " 10  Bwd Packet Length Max         int64  \n",
      " 11   Bwd Packet Length Min        int64  \n",
      " 12   Bwd Packet Length Mean       float64\n",
      " 13   Bwd Packet Length Std        float64\n",
      " 14  Flow Bytes/s                  float64\n",
      " 15   Flow Packets/s               float64\n",
      " 16   Flow IAT Mean                float64\n",
      " 17   Flow IAT Std                 float64\n",
      " 18   Flow IAT Max                 int64  \n",
      " 19   Flow IAT Min                 int64  \n",
      " 20  Fwd IAT Total                 int64  \n",
      " 21   Fwd IAT Mean                 float64\n",
      " 22   Fwd IAT Std                  float64\n",
      " 23   Fwd IAT Max                  int64  \n",
      " 24   Fwd IAT Min                  int64  \n",
      " 25  Bwd IAT Total                 int64  \n",
      " 26   Bwd IAT Mean                 float64\n",
      " 27   Bwd IAT Std                  float64\n",
      " 28   Bwd IAT Max                  int64  \n",
      " 29   Bwd IAT Min                  int64  \n",
      " 30  Fwd PSH Flags                 int64  \n",
      " 31   Bwd PSH Flags                int64  \n",
      " 32   Fwd URG Flags                int64  \n",
      " 33   Bwd URG Flags                int64  \n",
      " 34   Fwd Header Length            int64  \n",
      " 35   Bwd Header Length            int64  \n",
      " 36  Fwd Packets/s                 float64\n",
      " 37   Bwd Packets/s                float64\n",
      " 38   Min Packet Length            int64  \n",
      " 39   Max Packet Length            int64  \n",
      " 40   Packet Length Mean           float64\n",
      " 41   Packet Length Std            float64\n",
      " 42   Packet Length Variance       float64\n",
      " 43  FIN Flag Count                int64  \n",
      " 44   SYN Flag Count               int64  \n",
      " 45   RST Flag Count               int64  \n",
      " 46   PSH Flag Count               int64  \n",
      " 47   ACK Flag Count               int64  \n",
      " 48   URG Flag Count               int64  \n",
      " 49   CWE Flag Count               int64  \n",
      " 50   ECE Flag Count               int64  \n",
      " 51   Down/Up Ratio                int64  \n",
      " 52   Average Packet Size          float64\n",
      " 53   Avg Fwd Segment Size         float64\n",
      " 54   Avg Bwd Segment Size         float64\n",
      " 55   Fwd Header Length.1          int64  \n",
      " 56  Fwd Avg Bytes/Bulk            int64  \n",
      " 57   Fwd Avg Packets/Bulk         int64  \n",
      " 58   Fwd Avg Bulk Rate            int64  \n",
      " 59   Bwd Avg Bytes/Bulk           int64  \n",
      " 60   Bwd Avg Packets/Bulk         int64  \n",
      " 61  Bwd Avg Bulk Rate             int64  \n",
      " 62  Subflow Fwd Packets           int64  \n",
      " 63   Subflow Fwd Bytes            int64  \n",
      " 64   Subflow Bwd Packets          int64  \n",
      " 65   Subflow Bwd Bytes            int64  \n",
      " 66  Init_Win_bytes_forward        int64  \n",
      " 67   Init_Win_bytes_backward      int64  \n",
      " 68   act_data_pkt_fwd             int64  \n",
      " 69   min_seg_size_forward         int64  \n",
      " 70  Active Mean                   float64\n",
      " 71   Active Std                   float64\n",
      " 72   Active Max                   int64  \n",
      " 73   Active Min                   int64  \n",
      " 74  Idle Mean                     float64\n",
      " 75   Idle Std                     float64\n",
      " 76   Idle Max                     int64  \n",
      " 77   Idle Min                     int64  \n",
      " 78   Label                        object \n",
      "dtypes: float64(24), int64(54), object(1)\n",
      "memory usage: 1.7+ GB\n"
     ]
    }
   ],
   "source": [
    "# Display data types\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783bacf",
   "metadata": {},
   "source": [
    "By checking the data types, it is safe to assume the dataset countains only metric features, considering 'Label' as 'y' (the only categorical column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0095eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Flow Bytes/s' has 1358 missing values, which is 0.05% of the total\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "missing_values = data.isna().sum()\n",
    "missing_percentage = (missing_values / len(data)) * 100\n",
    "\n",
    "# Printing columns with missing values\n",
    "for column, count in missing_values.items():\n",
    "    if count != 0:\n",
    "        print(f\"Column '{column}' has {count} missing values, which is {missing_percentage[column]:.2f}% of the total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c38e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 308381\n"
     ]
    }
   ],
   "source": [
    "# Checking and counting duplicates\n",
    "duplicates = data.duplicated()\n",
    "duplicate_count = duplicates.sum()\n",
    "\n",
    "# Output results\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23cad2",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1ffcb8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of leading/trailing whitespace\n",
    "col_names = {col: col.strip() for col in data.columns}\n",
    "data.rename(columns = col_names, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9821d1",
   "metadata": {},
   "source": [
    "# 3.1. Duplicates and Infinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13126557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 308381\n"
     ]
    }
   ],
   "source": [
    "# Checking and counting duplicates\n",
    "duplicates = data.duplicated()\n",
    "duplicate_count = duplicates.sum()\n",
    "\n",
    "# Output results\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056396f4",
   "metadata": {},
   "source": [
    "Removing duplicates from a dataset is often considered safe and beneficial as it enhances data integrity, improves statistical accuracy, increases efficiency, and simplifies analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d915af66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2522362, 79)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removal of duplicates\n",
    "data = data.drop_duplicates(keep='first')\n",
    "del duplicates\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8084187",
   "metadata": {},
   "source": [
    "The same can be done for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1693876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identical columns found:\n",
      "'Total Fwd Packets' is identical to ['Subflow Fwd Packets']\n",
      "'Total Backward Packets' is identical to ['Subflow Bwd Packets']\n",
      "'Fwd PSH Flags' is identical to ['SYN Flag Count']\n",
      "'Bwd PSH Flags' is identical to ['Bwd URG Flags', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
      "'Fwd URG Flags' is identical to ['CWE Flag Count']\n",
      "'Fwd Header Length' is identical to ['Fwd Header Length.1']\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with identical data\n",
    "identical_columns = {}\n",
    "columns = data.columns\n",
    "list_control = columns.copy().tolist()\n",
    "\n",
    "# Compare each pair of columns\n",
    "for col1 in columns:\n",
    "    for col2 in columns:\n",
    "        if col1 != col2:\n",
    "            if data[col1].equals(data[col2]):\n",
    "                if (col1 not in identical_columns) and (col1 in list_control):\n",
    "                    identical_columns[col1] = [col2]\n",
    "                    list_control.remove(col2)\n",
    "                elif (col1 in identical_columns) and (col1 in list_control):\n",
    "                    identical_columns[col1].append(col2)\n",
    "                    list_control.remove(col2)\n",
    "\n",
    "# Print the result\n",
    "if identical_columns:\n",
    "    print(\"Identical columns found:\")\n",
    "    for key, value in identical_columns.items():\n",
    "        print(f\"'{key}' is identical to {value}\")\n",
    "else: print(\"No identical columns found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80fc28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns with duplicated values\n",
    "for key, value in identical_columns.items():\n",
    "    data.drop(columns=value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6664dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
      "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
      "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
      "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
      "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
      "       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
      "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
      "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
      "       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
      "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
      "       'Fwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\n",
      "       'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length',\n",
      "       'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\n",
      "       'Packet Length Variance', 'FIN Flag Count', 'RST Flag Count',\n",
      "       'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'ECE Flag Count',\n",
      "       'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
      "       'Avg Bwd Segment Size', 'Subflow Fwd Bytes', 'Subflow Bwd Bytes',\n",
      "       'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'act_data_pkt_fwd',\n",
      "       'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max',\n",
      "       'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2522362, 67)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3129c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Bytes/s      1211\n",
      "Flow Packets/s    1564\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for infinite values\n",
    "num_columns = data.select_dtypes(include = np.number).columns\n",
    "has_infinite = np.isinf(data[num_columns]).sum()\n",
    "print(has_infinite[has_infinite > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e67f3",
   "metadata": {},
   "source": [
    "Removing infinite values is typically safe and beneficial, as it enhances data integrity, ensures statistical accuracy, aids in proper model training, and clarifies insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "488a2e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating infinite values\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c956a8e",
   "metadata": {},
   "source": [
    "# 3.1 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06401f5f",
   "metadata": {},
   "source": [
    "There are different approaches to dealing with missing values. The first step in identifying how to proceed is to understand their impact on the dataset. Here, we will do that by analyzing the y column (Label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d37508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>Number of Occurrences</th>\n",
       "      <th>Occurrences w/o Null Rows</th>\n",
       "      <th>Abs Difference</th>\n",
       "      <th>Difference %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BENIGN</td>\n",
       "      <td>2096484</td>\n",
       "      <td>2095057</td>\n",
       "      <td>1427</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DoS Hulk</td>\n",
       "      <td>172849</td>\n",
       "      <td>172846</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDoS</td>\n",
       "      <td>128016</td>\n",
       "      <td>128014</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PortScan</td>\n",
       "      <td>90819</td>\n",
       "      <td>90694</td>\n",
       "      <td>125</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DoS GoldenEye</td>\n",
       "      <td>10286</td>\n",
       "      <td>10286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FTP-Patator</td>\n",
       "      <td>5933</td>\n",
       "      <td>5931</td>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DoS slowloris</td>\n",
       "      <td>5385</td>\n",
       "      <td>5385</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DoS Slowhttptest</td>\n",
       "      <td>5228</td>\n",
       "      <td>5228</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SSH-Patator</td>\n",
       "      <td>3219</td>\n",
       "      <td>3219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bot</td>\n",
       "      <td>1953</td>\n",
       "      <td>1948</td>\n",
       "      <td>5</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Web Attack � Brute Force</td>\n",
       "      <td>1470</td>\n",
       "      <td>1470</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Web Attack � XSS</td>\n",
       "      <td>652</td>\n",
       "      <td>652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Infiltration</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Web Attack � Sql Injection</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heartbleed</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Attack Type  Number of Occurrences  \\\n",
       "0                       BENIGN                2096484   \n",
       "1                     DoS Hulk                 172849   \n",
       "2                         DDoS                 128016   \n",
       "3                     PortScan                  90819   \n",
       "4                DoS GoldenEye                  10286   \n",
       "5                  FTP-Patator                   5933   \n",
       "6                DoS slowloris                   5385   \n",
       "7             DoS Slowhttptest                   5228   \n",
       "8                  SSH-Patator                   3219   \n",
       "9                          Bot                   1953   \n",
       "10    Web Attack � Brute Force                   1470   \n",
       "11            Web Attack � XSS                    652   \n",
       "12                Infiltration                     36   \n",
       "13  Web Attack � Sql Injection                     21   \n",
       "14                  Heartbleed                     11   \n",
       "\n",
       "    Occurrences w/o Null Rows  Abs Difference  Difference %  \n",
       "0                     2095057            1427          0.07  \n",
       "1                      172846               3          0.00  \n",
       "2                      128014               2          0.00  \n",
       "3                       90694             125          0.14  \n",
       "4                       10286               0          0.00  \n",
       "5                        5931               2          0.03  \n",
       "6                        5385               0          0.00  \n",
       "7                        5228               0          0.00  \n",
       "8                        3219               0          0.00  \n",
       "9                        1948               5          0.26  \n",
       "10                       1470               0          0.00  \n",
       "11                        652               0          0.00  \n",
       "12                         36               0          0.00  \n",
       "13                         21               0          0.00  \n",
       "14                         11               0          0.00  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attack counts\n",
    "attack_counts = data['Label'].value_counts().reset_index()\n",
    "attack_counts.columns = ['Attack Type', 'Number of Occurrences']\n",
    "\n",
    "# Duplicating the df and dropping rows with missing values\n",
    "data_no_na = data.dropna()\n",
    "\n",
    "# Counting the total number of occurrences of each attack after dropping\n",
    "occurrences_nonull = data_no_na['Label'].value_counts().reset_index()\n",
    "occurrences_nonull.columns = ['Attack Type', 'Occurrences w/o Null Rows']\n",
    "\n",
    "# Merging the DataFrames\n",
    "attack_counts = attack_counts.merge(occurrences_nonull, on='Attack Type', how='left')\n",
    "\n",
    "# Calculating the difference\n",
    "attack_counts['Abs Difference'] = attack_counts['Number of Occurrences'] - attack_counts['Occurrences w/o Null Rows']\n",
    "attack_counts['Difference %'] = ((attack_counts['Abs Difference'] * 100) / attack_counts['Number of Occurrences']).round(2)\n",
    "\n",
    "# Visualization\n",
    "attack_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "009658c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no columns with missing values greater than the threshold\n"
     ]
    }
   ],
   "source": [
    "# Cleaning up\n",
    "del data_no_na\n",
    "\n",
    "# Evaluating percentage of missing values per column\n",
    "threshold = 10\n",
    "missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "\n",
    "# Filter columns with missing values over the threshold\n",
    "high_missing_cols = missing_percentage[missing_percentage > threshold]\n",
    "\n",
    "# Print columns with high missing percentages\n",
    "if len(high_missing_cols) > 0:\n",
    "    print(f'The following columns have over {threshold}% of missing values:')\n",
    "    print(high_missing_cols)\n",
    "else:\n",
    "    print('There are no columns with missing values greater than the threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dfd6a1",
   "metadata": {},
   "source": [
    "The analysis of missing values across the dataset suggests that missing values are not heavily concentrated in any single column and that the dataset can tolerate row-wise removal without significant impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa0425ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.522362e+06\n",
      "mean     1.850907e-03\n",
      "std      7.430795e-02\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      2.985075e+00\n",
      "dtype: float64\n",
      "\n",
      "Total rows with missing values: 1564\n"
     ]
    }
   ],
   "source": [
    "row_missing_percentage = (data.isna().sum(axis=1) / data.shape[1]) * 100\n",
    "print(row_missing_percentage.describe())\n",
    "\n",
    "missing_rows = data.isna().any(axis=1).sum()\n",
    "print(f'\\nTotal rows with missing values: {missing_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0d3a0",
   "metadata": {},
   "source": [
    "Following previous studies, such as Panigrahi and Borah (2018), and considering the minimal impact of removing rows with missing values (concentrated on the Benign class), we will proceed to drop these rows from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8249a258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after row-wise removal: (2520798, 67)\n"
     ]
    }
   ],
   "source": [
    "# Dropping missing values\n",
    "data = data.dropna()\n",
    "print(f'Dataset shape after row-wise removal: {data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed95dd7",
   "metadata": {},
   "source": [
    "# 3.2 Data-Driven Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a529fb",
   "metadata": {},
   "source": [
    "The idea here is to perform a straightforward manual feature selection process that focuses on examining the dataset critically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d69a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bwd PSH Flags\n",
      "\n",
      "The number of columns with only one unique values is: 1\n"
     ]
    }
   ],
   "source": [
    "# Check for numeric columns that contain only a single unique value, indicating no diversity in values.\n",
    "# Such columns contribute no useful information to the analysis and may be candidates for removal.\n",
    "only_unique_cols = []\n",
    "for col in data.columns:\n",
    "    if len(data[col].unique()) == 1:\n",
    "        only_unique_cols.append(col)\n",
    "        print(col)\n",
    "\n",
    "print(f'\\nThe number of columns with only one unique values is: {len(only_unique_cols)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ea0c4",
   "metadata": {},
   "source": [
    "Columns with only a single unique value can typically be removed from the dataset before training machine learning models without risk of loss of relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e53f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns with only one unique value\n",
    "data.drop(only_unique_cols, axis=1, inplace=True)\n",
    "del only_unique_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e654a421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520798, 66)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the new shape after cleaning\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaed7c8b",
   "metadata": {},
   "source": [
    "## 3.3. Grouping/ Removing Attack Types\n",
    "\n",
    "As seen previously, the dataset categorizes various types of attacks into distinct groups, including different variations of Denial of Service (DoS) attacks. Given the imbalance present in the dataset, consolidating these classes could enhance the training process of ML models. This approach allows models to learn from a more balanced representation of the data, potentially improving classification accuracy and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8873b6e",
   "metadata": {},
   "source": [
    "### 3.3.1. Grouping attack types\n",
    "\n",
    "The table below illustrates the proposed grouping of attack categories. For now, DoS and DDoS will remain separate due to their distinct characteristics, such as differences in attack methodology and mitigation strategies, which could impact the model's performance and interpretation.\n",
    "\n",
    "\n",
    "| **Group**                     | **Attack Type**             | **Count**  |  \n",
    "|-------------------------------|-----------------------------|------------|  \n",
    "| **Normal Traffic**            | BENIGN                      | 2,095,057  |  \n",
    "|                               |                             | **Total: 2,095,057** |  \n",
    "| **DoS Attacks**              | DoS Hulk                   | 172,846    |  \n",
    "|                               | DoS GoldenEye               | 10,286     |  \n",
    "|                               | DoS Slowloris               | 5,385      |  \n",
    "|                               | DoS Slowhttptest            | 5,228      |\n",
    "|                               |                             | **Total: 193,745** |\n",
    "| **DDoS Attacks**              | DDoS                        | 128,014     |\n",
    "|                               |                             | **Total: 128,014** |\n",
    "| **Port Scanning**            | PortScan                    | 90,694     |  \n",
    "|                               |                             | **Total: 90,694**  |  \n",
    "| **Brute Force Attacks**      | FTP-Patator                 | 5,931      |  \n",
    "|                               | SSH-Patator                 | 3,219      |  \n",
    "|                               |                             | **Total: 9,150**   |  \n",
    "| **Bots**                      | Bot                         | 1,948      |  \n",
    "|                               |                             | **Total: 1,948**   |  \n",
    "| **Web Attacks**              | Web Attack – Brute Force    | 1,470      |  \n",
    "|                               | Web Attack – XSS            | 652        |  \n",
    "|                               | Web Attack – SQL Injection   | 21         |  \n",
    "|                               |                             | **Total: 2,143**   |  \n",
    "| **Infiltration Attacks**     | Infiltration                | 36         |  \n",
    "|                               |                             | **Total: 36**      |  \n",
    "| **Miscellaneous**            | Heartbleed                  | 11         |  \n",
    "|                               |                             | **Total: 11**      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a35c452",
   "metadata": {},
   "source": [
    "# Mapping the attacks to the new group\n",
    "group_mapping = {\n",
    "    'BENIGN': 'Normal Traffic',\n",
    "    'DoS Hulk': 'DoS',\n",
    "    'DDoS': 'DDoS',\n",
    "    'PortScan': 'Port Scanning',\n",
    "    'DoS GoldenEye': 'DoS',\n",
    "    'FTP-Patator': 'Brute Force',\n",
    "    'DoS slowloris': 'DoS',\n",
    "    'DoS Slowhttptest': 'DoS',\n",
    "    'SSH-Patator': 'Brute Force',\n",
    "    'Bot': 'Bots',\n",
    "    'Web Attack � Brute Force': 'Web Attacks',\n",
    "    'Web Attack � XSS': 'Web Attacks',\n",
    "    'Infiltration': 'Infiltration',\n",
    "    'Web Attack � Sql Injection': 'Web Attacks',\n",
    "    'Heartbleed': 'Miscellaneous'\n",
    "}\n",
    "\n",
    "# Map to new group column\n",
    "data['Attack Type'] = data['Label'].map(group_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae04c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the attacks to the new group\n",
    "group_mapping = {\n",
    "    'BENIGN': 'Normal Traffic',\n",
    "    'DoS Hulk': 'DoS',\n",
    "    'DDoS': 'DDoS',\n",
    "    'PortScan': 'Port Scanning',\n",
    "    'DoS GoldenEye': 'DoS',\n",
    "    'FTP-Patator': 'Brute Force',\n",
    "    'DoS slowloris': 'DoS',\n",
    "    'DoS Slowhttptest': 'DoS',\n",
    "    'SSH-Patator': 'Brute Force',\n",
    "    'Bot': 'Bots',\n",
    "    'Web Attack � Brute Force': 'Web Attacks',\n",
    "    'Web Attack � XSS': 'Web Attacks',\n",
    "    'Infiltration': 'Infiltration',\n",
    "    'Web Attack � Sql Injection': 'Web Attacks',\n",
    "    'Heartbleed': 'Miscellaneous'\n",
    "}\n",
    "\n",
    "# Map to new group column\n",
    "data['Attack Type'] = data['Label'].map(group_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a504f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the old 'Label' column\n",
    "data.drop(columns='Label', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167722b1",
   "metadata": {},
   "source": [
    "### 3.3.2. Removal of Attack Types\n",
    "\n",
    "Given the very low instance counts for 'Infiltration' (36) and 'Heartbleed' (11), it is advisable to remove these categories from the dataset as they can lead to overfitting and unreliable model performance, even techniques like SMOTE may not be sufficient to create a representative training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11feb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows with statistically irrelevant attack types\n",
    "data.drop(data[(data['Attack Type'] == 'Infiltration') | (data['Attack Type'] == 'Miscellaneous')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba54f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520751, 66)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Attack Type\n",
       "Normal Traffic    2095057\n",
       "DoS                193745\n",
       "DDoS               128014\n",
       "Port Scanning       90694\n",
       "Brute Force          9150\n",
       "Web Attacks          2143\n",
       "Bots                 1948\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data shape and attack counts after removal\n",
    "print(data.shape)\n",
    "data['Attack Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "357e83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows with statistically irrelevant attack types\n",
    "data.drop(data[(data['Attack Type'] == 'Infiltration') | (data['Attack Type'] == 'Miscellaneous')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26dcd8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520751, 66)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Attack Type\n",
       "Normal Traffic    2095057\n",
       "DoS                193745\n",
       "DDoS               128014\n",
       "Port Scanning       90694\n",
       "Brute Force          9150\n",
       "Web Attacks          2143\n",
       "Bots                 1948\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data shape and attack counts after removal\n",
    "print(data.shape)\n",
    "data['Attack Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
